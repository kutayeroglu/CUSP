{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1915,"status":"ok","timestamp":1746610740743,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"},"user_tz":-180},"id":"ng1f_uU-LOGY","outputId":"26cc4503-13c6-494d-d2e1-255a64afeab0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'CUSP'...\n","remote: Enumerating objects: 246, done.\u001b[K\n","remote: Counting objects: 100% (43/43), done.\u001b[K\n","remote: Compressing objects: 100% (36/36), done.\u001b[K\n","remote: Total 246 (delta 12), reused 35 (delta 7), pack-reused 203 (from 2)\u001b[K\n","Receiving objects: 100% (246/246), 23.93 MiB | 38.53 MiB/s, done.\n","Resolving deltas: 100% (95/95), done.\n","/content/CUSP\n"]}],"source":["!git clone https://github.com/kutayeroglu/CUSP\n","%cd CUSP"]},{"cell_type":"markdown","metadata":{"id":"PbzupEtVO_R7"},"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5417,"status":"ok","timestamp":1746610746163,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"},"user_tz":-180},"id":"7IdsVFG9RBpI","outputId":"79b82ca3-1254-43d3-9f90-220d0543ed6f"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"]}],"source":["import os\n","import time\n","import pickle\n","\n","import torch\n","import torch.nn.functional as F\n","\n","import PIL.Image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Custom modules\n","from training.networks import VGG, module_no_grad\n","import legacy\n","from torch_utils import misc\n","import dnnlib\n","\n","# GDrive authentication and Download\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials"]},{"cell_type":"markdown","metadata":{"id":"VHmJ0FwkTvMr"},"source":["# Google Drive\n","First we configure GDrive for model download.\n","\n","Authenticated downloads prevent Google from blocking the file."]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":107131,"status":"ok","timestamp":1746610853295,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"},"user_tz":-180},"id":"Q3SCBp2qRFDt"},"outputs":[],"source":["auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)"]},{"cell_type":"markdown","metadata":{"id":"x0-KiYyMpjDp"},"source":["# Running configuration\n","\n","```KEY``` defines the running model. The options are:\n","- ```FFHQ_RR_KEY``` for FFHQ-RR dataset (20 to 69)\n","- ```FFHQ_LS_KEY``` for FFHQ-LS dataset (binarized 0 to 100)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1746610853304,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"},"user_tz":-180},"id":"_t72UxLFT_2p"},"outputs":[],"source":["FFHQ_LS_KEY = \"lats\"  # Model trained on LATS dataset\n","FFHQ_RR_KEY = \"hrfae\" # Model trained on HRFAE dataset\n","\n","# Choose one from above\n","# KEY = FFHQ_RR_KEY # [HRFAE_KEY or LATS_KEY]\n","KEY = FFHQ_LS_KEY # [HRFAE_KEY or LATS_KEY]\n","\n","# Config and GDrive ID\n","vgg_path_gdrive_id = '1a0jghZx44uC_kIIvD-UEcNp4Xz8Bpso1'\n","configs = {\n","    FFHQ_LS_KEY: dict(\n","        gdrive_id=\"1sWSH3tHgm9DkHrc19hoEMrR-KQgnaFuw\",\n","        side=256,\n","        classes=(1,8)),\n","    FFHQ_RR_KEY: dict(\n","        gdrive_id=\"17BOTEa6z3r6JFVs1KDutDxWEkTWbzaeD\",\n","        side=224,\n","        classes=(20,65))\n","}\n","\n","# CUDA device\n","device = torch.device('cuda',0)\n","# Images path\n","sample_images_path= \"sample_images\" # Samples are taken from FFHQ\n","# Model GDrive ID\n","model_id = configs[KEY]['gdrive_id']\n","# Side of input images\n","img_side = configs[KEY]['side']\n","# Labels range for examples generation\n","data_labels_range = configs[KEY]['classes']\n","# Read image filenames\n","filenames_batch = [\n","      os.path.join(sample_images_path,f)\n","      for  f in next(iter(os.walk(sample_images_path)))[2]\n","      if f[-4:] == '.png'\n","    ]"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":111,"status":"ok","timestamp":1746610853416,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"},"user_tz":-180},"id":"nJkzlPMmnDwS"},"outputs":[],"source":["!rm ./custom_images/margaret-hamilton.png"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1746610853420,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"},"user_tz":-180},"id":"MRnQeHfjM6dm"},"outputs":[],"source":["# custom_images_path = \"/content/drive/MyDrive/masters/2024_25-02/biometrics/cusp_input\"\n","\n","# custom_filenames_batch = [\n","#     os.path.join(sample_images_path, f)\n","#     for f in os.listdir(custom_images_path)\n","#     if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n","# ]\n","\n","# # Add error handling for empty directories\n","# if not custom_filenames_batch:\n","#     raise FileNotFoundError(f\"No images found in {custom_filenames_batch}. \"\n","#                             \"Ensure: 1) Drive mounted correctly, \"\n","#                             \"2) Images are PNG/JPG, 3) Path is correct\")\n","\n","# print(filenames_batch)\n","\n","custom_images_path = \"custom_images\"\n","\n","custom_filenames_batch = [\n","    os.path.join(custom_images_path, f)\n","    for f in next(iter(os.walk(custom_images_path)))[2]\n","    if f[-4:] in ['.jpg', '.png', 'jpeg']\n","]"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":147,"status":"ok","timestamp":1746610853568,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"},"user_tz":-180},"id":"_FScH6Kpno9g","outputId":"02d843e8-bba5-4e15-f0cd-92947650c458"},"outputs":[{"output_type":"stream","name":"stdout","text":["01_22_aligned.png  clint.png  culkin.png  preprocessor.py  zizek.png\n"]}],"source":["!ls ./custom_images/"]},{"cell_type":"markdown","metadata":{"id":"cnhnOmuxr8rb"},"source":["The pretrained serialized models are downloaded from Google Drive"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tcukE7yuV3qy","executionInfo":{"status":"ok","timestamp":1746610947084,"user_tz":-180,"elapsed":93515,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"}},"outputId":"7b294fb3-f016-4138-ada6-01cbc9d8fd94"},"outputs":[{"output_type":"stream","name":"stdout","text":["File dex_imdb_wiki.caffemodel.pt (1a0jghZx44uC_kIIvD-UEcNp4Xz8Bpso1) downloaded to dex_imdb_wiki.caffemodel.pt in 22.952357292175293 seconds\n","File network-snapshot-005780.pkl (1sWSH3tHgm9DkHrc19hoEMrR-KQgnaFuw) downloaded to pretrained.pkl in 70.48561334609985 seconds\n"]}],"source":["def download_gdrive_id(gid, file_path):\n","  begin = time.time()\n","  gfile = drive.CreateFile(dict(id=gid))\n","  gfile.GetContentFile(file_path)\n","\n","  print(f\"File {gfile['title']} ({gid}) downloaded to {file_path} in {time.time()-begin} seconds\")\n","# Destination paths\n","weights_path = \"pretrained.pkl\"\n","vgg_path = \"dex_imdb_wiki.caffemodel.pt\"\n","# Download models\n","download_gdrive_id(vgg_path_gdrive_id,vgg_path)\n","download_gdrive_id(model_id,weights_path)"]},{"cell_type":"markdown","metadata":{"id":"XwCKVOMgsK-K"},"source":["The network snapshop downloaded from ```model_id``` has 4 (key,values) tuples:\n","- ```G```: Generator weights on last training iteration\n","- ```G_ema```: Exponential moving average for the generator weights. It yields a more stable model for generation. (**THIS IS THE ONE WE'LL USE**)\n","- ```D```: Discriminator weights\n","- ```config```: Some training configuration parameters\n","\n","Then we have to load the DEX age classifier, disable gradients, and add it to the Generator."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"xBOIzUudX3En","executionInfo":{"status":"ok","timestamp":1746610956728,"user_tz":-180,"elapsed":9643,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"}}},"outputs":[],"source":["def load_model(model_path,vgg_path,device):\n","    with open(model_path,'rb') as f:\n","        contents = legacy.load_network_pkl(f) # Pickles weights and source code\n","\n","    # Get exponential movign average model\n","    G_ema = contents['G_ema']\n","\n","    # Load DEX VGG classifier\n","    vgg = VGG()\n","    vgg_state_dict = torch.load(vgg_path)\n","    vgg_state_dict = {k.replace('-', '_'): v for k, v in vgg_state_dict.items()}\n","    vgg.load_state_dict(vgg_state_dict)\n","    module_no_grad(vgg) #!important\n","\n","    # Set classifier\n","    G_ema.skip_grad_blur.model.classifier = vgg\n","    # No grad\n","    G_ema = G_ema.to(device).eval().requires_grad_(False)\n","    # No grad on VGG\n","\n","    return G_ema\n","\n","G_ema = load_model(\n","    weights_path,\n","    vgg_path,\n","    device)"]},{"cell_type":"markdown","metadata":{"id":"0QeLvsVltt5I"},"source":["The image generation process is comprised of several steps:\n","- Input images are run through the Content Encoder and the Style Encoder.\n","- Target age labels are One-Hot encoded and run through the Age Mapping network.\n","- Global blur and CUSP masked blur are applied on the skip connections.\n","- The decoder is fed with the Content Encoder 2D tensors and the Age/Style 1D embedding."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"uoau0hR-XqL4","executionInfo":{"status":"ok","timestamp":1746610956742,"user_tz":-180,"elapsed":3,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"}}},"outputs":[],"source":["def run_model(G, img, label, global_blur_val=None, mask_blur_val=None, return_msk = False):\n","    # Tranform label to One Hot Encoding\n","    cls = torch.nn.functional.one_hot(\n","        torch.tensor(label),\n","        num_classes=G.attr_map.fc0.init_args[0]\n","    ).to(img.device)\n","\n","    # Content encoder\n","    _,c_out_skip = G.content_enc(img)\n","\n","    # Style encodder\n","    s_out = G.style_enc(img)[0].mean((2, 3))\n","\n","    truncation_psi=1\n","    truncation_cutoff=None\n","    s_out = G.style_map(s_out, None, truncation_psi, truncation_cutoff)\n","\n","    # age mapping\n","    a_out = G.attr_map(cls.to(s_out.device), None, truncation_psi, truncation_cutoff)\n","\n","    # Style mapping and Age mapping are interleaved for the corresponding\n","    # weight demodulation modules\n","    w = G.__interleave_attr_style__(a_out, s_out)\n","\n","    # Global blur\n","    for i,(f,_) in enumerate(zip(G.skip_transf, c_out_skip)):\n","        if f is not None:\n","            c_out_skip[i] = G._batch_blur(c_out_skip[i], blur_val = global_blur_val)\n","\n","    # Masked blur\n","    cam = G.skip_grad_blur(img.float())\n","    msk = cam\n","    for i, (f, c) in enumerate(zip(G.skip_transf, c_out_skip)):\n","        if f is not None:\n","            im_size = c.size(-1)\n","            blur_c = G._batch_blur(c, blur_val= mask_blur_val)\n","            if msk.size(2) != im_size:\n","                msk = F.interpolate(msk,size=(im_size,im_size), mode='area')\n","            merged_c = c * msk + blur_c * (1 - msk)\n","            c_out_skip[i] = merged_c\n","\n","\n","    # Decoder\n","    img_out = G.image_dec(c_out_skip, w)\n","\n","    if return_msk:\n","        to_return = (img_out,msk,cam) if G.learn_mask is not None else (img_out,None,None)\n","    else:\n","        to_return = img_out\n","\n","    # assert(all(x.grad is None for x in G.parameters()))\n","    # assert(all(x.grad is None for x in G.skip_grad_blur.model.get_classifier().parameters()))\n","    # G.zero_grad()\n","\n","    return to_return"]},{"cell_type":"markdown","metadata":{"id":"k1gMVenkvbIh"},"source":["Data is prepared to be fed to the Generator. The number of steps for this examples is defined dynamically by ```steps```."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"QzvnA-ZngGGr","executionInfo":{"status":"ok","timestamp":1746610956745,"user_tz":-180,"elapsed":1,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"}}},"outputs":[],"source":["import numpy as np\n","import PIL\n","from PIL import Image, ImageOps, ImageFilter\n","\n","def preprocess_images(filenames, side):\n","    processed_imgs = []\n","\n","    for f in filenames:\n","        # Open and resize the image\n","        img = Image.open(f).resize((side, side))\n","\n","        # Ensure image is RGB (3 channels) - removes alpha if present\n","        if img.mode != 'RGB':\n","            img = img.convert('RGB')\n","\n","        # Convert to numpy array\n","        img_array = np.array(img, dtype=np.float32)\n","\n","        # Transpose from HWC to CHW format (what PyTorch expects)\n","        img_array = img_array.transpose((2, 0, 1))\n","\n","        processed_imgs.append(img_array)\n","\n","    return processed_imgs\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ZvyKLJ1zdmZ2","executionInfo":{"status":"ok","timestamp":1746610956862,"user_tz":-180,"elapsed":115,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"}}},"outputs":[],"source":["# Image side\n","side = configs[KEY]['side']\n","# Read & preprocess images\n","imgs = preprocess_images(custom_filenames_batch, side)\n","\n","# Transform to tensors\n","im_in_tensor = (torch.tensor(np.array(imgs))/256*2-1).cuda() # Values {-1,1}\n","\n","# Aging steps\n","steps = 6 # N steps\n","# Repeat images N times\n","n_images = im_in_tensor.shape[0]\n","im_in_tensor_exp = im_in_tensor[:,None].expand([n_images,steps,*im_in_tensor.shape[1:]]).reshape([-1,*im_in_tensor.shape[1:]])\n","# Define target ages\n","labels_exp = torch.tensor(np.repeat(np.linspace(*data_labels_range,steps,dtype=int)[:,None],n_images,1).T.reshape(-1))"]},{"cell_type":"markdown","metadata":{"id":"LId62pnSvvkh"},"source":["In a batch-sized fashion we run our data through the model.\n","\n","The two parameters for the CUSP module range from 0 to 1 and are the following:\n","- ```global_blur_val```: Global blur applied on the skip connection.\n","- ```mask_blur_val```: Guided-backpropagation-based masking on age specific areas.\n","\n","The Custom Preservation (CP) config corresponds to ```global_blur_val=0.2``` and ```mask_blur_val=0.8```\n","\n","_The output of this window is not shown to hide the printed warnings. The code needs to be run in its corresponding Pytorch Docker environment to run efficiently with Nvidia custom CUDA modules._"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"9-xGDbFXdoWx","executionInfo":{"status":"ok","timestamp":1746610959606,"user_tz":-180,"elapsed":2738,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"}}},"outputs":[],"source":["%%capture\n","batch_size = 12\n","# Run model\n","im_out_tensor_exp = torch.concat([run_model(\n","    G_ema,\n","    mini_im,\n","    mini_label,\n","    global_blur_val=0.2, # CUSP global blur\n","    mask_blur_val=0.8)   # CUSP masked blur\n","    for mini_im, mini_label\n","    in zip(\n","        im_in_tensor_exp.split(batch_size),\n","        labels_exp.split(batch_size)\n","    )])\n","# Transform to [batch_size, N_ages, W, H , C]\n","im_out_tensor = im_out_tensor_exp.reshape([-1,steps,*im_out_tensor_exp.shape[1:]])"]},{"cell_type":"markdown","metadata":{"id":"_VlZ1A9jwhnh"},"source":["The result is laid out in 5 columns, from left to right: Input Image and Steps 1 to 4 from the corresponing age label range defined in ```configs[KEY]['classes']```.\n","\n","_Labels are meaningless on FFHQ-LS, you should refer to LATS work for the corresponding bins' age brackets_"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"output_embedded_package_id":"1r7XAGoGC-DYsCHOPRUwNsthT0V6Ies0I","base_uri":"https://localhost:8080/","height":856},"id":"y5Z7Ocs6dtyH","outputId":"405bb987-7631-4746-d752-f3786104b1ed","executionInfo":{"status":"ok","timestamp":1746610962143,"user_tz":-180,"elapsed":2538,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Transform tensor to uint8 image\n","def to_uint8(im_tensor):\n","    im_tensor = (im_tensor.detach().cpu().numpy().transpose((1,2,0))+1)*(256/2)\n","    im_tensor = np.clip(im_tensor,0,255).astype(np.uint8)\n","    return im_tensor\n","# For every input image\n","for fname, im_in, im_out, age_labels in zip(\n","        filenames_batch,im_in_tensor,im_out_tensor,\n","        labels_exp.numpy().reshape(-1,steps)\n","        ):\n","    # Create figure\n","    fig,axs = plt.subplots(1,steps+1,figsize=(steps*4,4),dpi=100)\n","    age_labels = ['Input'] + [f'Label \"{i}\"' for i in age_labels]\n","    # For every [input,step...]\n","    for ax,im,l in zip(axs,[im_in,*im_out],age_labels):\n","        ax.axis('off')\n","        ax.imshow(to_uint8(im))\n","        ax.set_title(l,fontname='Liberation Serif')"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7hQCup5FuzfY","executionInfo":{"status":"ok","timestamp":1746610962179,"user_tz":-180,"elapsed":5,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"}},"outputId":"94acea1f-85a8-43b0-e750-4973b1bf980d"},"outputs":[{"output_type":"stream","name":"stdout","text":["calc_metrics.py\t\t     docker_run.sh   sample_images\n","cusp_custom_output.py\t     generate.py     STYLEGAN2ADA_LICENSE.txt\n","CUSP.ipynb\t\t     legacy.py\t     style_mixing.py\n","custom_images\t\t     outputs\t     torch_utils\n","dataset_tool.py\t\t     pretrained.pkl  training\n","dex_imdb_wiki.caffemodel.pt  projector.py    train.py\n","dnnlib\t\t\t     __pycache__\n","Dockerfile\t\t     README.md\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lzxFHV5pOzFH","executionInfo":{"status":"ok","timestamp":1746610962185,"user_tz":-180,"elapsed":4,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"}},"outputId":"52232026-5059-41b2-cb1e-b43ac60d983f"},"outputs":[{"output_type":"stream","name":"stdout","text":["01_22_aligned.png  clint.png  culkin.png  preprocessor.py  zizek.png\n"]}],"source":["!ls ./custom_images"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"kt0OKzYZO09u","executionInfo":{"status":"ok","timestamp":1746610962187,"user_tz":-180,"elapsed":2,"user":{"displayName":"Kutay Eroğlu","userId":"12425207516295289282"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1FM0u5E3M4D5zH9ru-OIQhR56vQqvkl1U","timestamp":1746074304907}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}